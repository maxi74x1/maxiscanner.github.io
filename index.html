<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <title>Web 3D Scanner Concept - SfM Attempt v2</title>
    <!-- OpenCV.js -->
    <script async src="https://docs.opencv.org/4.8.0/opencv.js" onload="onOpenCvScriptLoad();" type="text/javascript"></script>
    <!-- THREE.js -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    <!-- GLTFExporter for THREE.js -->
    <script src="https://cdn.jsdelivr.net/gh/mrdoob/three.js@r128/examples/js/exporters/GLTFExporter.js"></script>

    <style>
        body, html { margin: 0; padding: 0; overflow: hidden; background-color: #000; font-family: sans-serif; color: white; display: flex; flex-direction: column; align-items: center; justify-content: center; height: 100vh; }
        .app-container { position: relative; width: 100vw; height: 100vh; display: flex; align-items: center; justify-content: center; }
        .video-container { position: absolute; top: 0; left: 0; width: 100%; height: 100%; background-color: #111; }
        #videoFeed { width: 100%; height: 100%; object-fit: cover; display: block; }
        #overlayCanvas { position: absolute; top: 0; left: 0; width: 100%; height: 100%; z-index: 5; }
        .ui-controls { position: fixed; bottom: 10px; left: 50%; transform: translateX(-50%); z-index: 10; background-color: rgba(0,0,0,0.7); padding: 8px; border-radius: 8px; display: flex; flex-wrap: wrap; gap: 8px; align-items: center; justify-content: center; }
        .ui-controls button { padding: 8px 12px; border: none; background-color: #007bff; color: white; border-radius: 5px; cursor: pointer; font-size: 13px; }
        .ui-controls button:disabled { background-color: #555; cursor: not-allowed; }
        .ui-controls button:hover:not(:disabled) { background-color: #0056b3; }
        #status, #frameCount { margin: 0 5px; font-size: 12px; padding: 5px; background-color: rgba(0,0,0,0.5); border-radius: 3px; min-width: 80px; text-align: center; }
        #loadingIndicator { position: fixed; top: 50%; left: 50%; transform: translate(-50%, -50%); background-color: rgba(0,0,0,0.8); color: white; padding: 20px; border-radius: 10px; font-size: 16px; z-index: 100; display: none; text-align: center; }
    </style>
</head>
<body>
    <div id="loadingIndicator">Loading App Resources...</div>
    <div class="app-container">
        <div class="video-container">
            <video id="videoFeed" autoplay playsinline muted></video>
            <canvas id="overlayCanvas"></canvas>
        </div>
        <div class="ui-controls">
            <button id="initCameraButton">Init Camera</button>
            <button id="startScanButton" disabled>Start Scan</button>
            <button id="stopScanButton" disabled>Stop Scan</button>
            <button id="reconstructButton" disabled>Reconstruct 3D</button>
            <button id="exportButton" disabled>Export GLB</button>
            <div id="frameCount">Frames: 0</div>
            <div id="status">App loading...</div>
        </div>
    </div>

    <script type="text/javascript">
        // --- DOM Elements ---
        const video = document.getElementById('videoFeed');
        const overlayCanvas = document.getElementById('overlayCanvas');
        const overlayCtx = overlayCanvas.getContext('2d');
        const initCameraButton = document.getElementById('initCameraButton');
        const startScanButton = document.getElementById('startScanButton');
        const stopScanButton = document.getElementById('stopScanButton');
        const reconstructButton = document.getElementById('reconstructButton');
        const exportButton = document.getElementById('exportButton');
        const statusElement = document.getElementById('status');
        const frameCountElement = document.getElementById('frameCount');
        const loadingIndicator = document.getElementById('loadingIndicator');

        // --- App State ---
        let stream;
        let cvReady = false, threeReady = false;
        let orb, bfMatcher; // OpenCV objects
        let isScanning = false;
        let scanProcessIntervalId = null;
        const SCAN_INTERVAL_MS = 750;
        let scanFramesData = [];
        let displayKeypointsVector = null;
        let K_matrix = null, distCoeffs = null;
        let threeScene, threeCamera, threeRenderer, threePointsObject = null;

        // --- OpenCV Loading Logic ---
        let cvPollInterval = null;
        let cvPollCount = 0;
        const MAX_CV_POLLS = 50; // Wait up to 10 seconds (50 * 200ms)

        function onOpenCvScriptLoad() {
            console.log("OpenCV SCRIPT TAG onload event fired.");
            // This function is called when the script tag itself has loaded.
            // It doesn't guarantee 'cv' object is ready yet, that happens inside the script.
            // Start polling immediately as 'cv' might initialize very quickly after this.
            if (!cvReady) {
                startCvPolling();
            }
        }

        function initializeOpenCVComponents() {
            console.log("Attempting to initialize OpenCV components (ORB, BFMatcher).");
            try {
                orb = new cv.ORB(500);
                bfMatcher = new cv.BFMatcher(cv.NORM_HAMMING, false);
                cvReady = true; // Mark as truly ready
                updateStatus("OpenCV Ready.");
                console.log("OpenCV components initialized successfully.");
            } catch (e) {
                updateStatus("Error Initializing OpenCV Components");
                console.error("Error during new cv.ORB() or new cv.BFMatcher():", e);
                cvReady = false; // Explicitly mark as not ready
            }
            checkAppReady(); // Update UI based on cvReady state
        }

        function startCvPolling() {
            console.log("Starting polling for 'cv' object...");
            if (cvPollInterval) clearInterval(cvPollInterval); // Clear any existing poller

            cvPollInterval = setInterval(() => {
                cvPollCount++;
                console.log(`Polling for 'cv' (attempt ${cvPollCount}). Typeof cv: ${typeof cv}`);
                if (typeof cv !== 'undefined' && cv.getBuildInformation) {
                    console.log("OpenCV 'cv' object found and has getBuildInformation. Build info:", cv.getBuildInformation());
                    clearInterval(cvPollInterval);
                    cvPollInterval = null;
                    initializeOpenCVComponents();
                } else if (cvPollCount >= MAX_CV_POLLS) {
                    clearInterval(cvPollInterval);
                    cvPollInterval = null;
                    updateStatus("Error: OpenCV.js timed out loading.");
                    console.error("OpenCV.js 'cv' object did not become available after polling.");
                    cvReady = false; // Ensure it's marked as not ready
                    checkAppReady();
                }
            }, 200);
        }


        // --- Utility Functions ---
        function showLoading(message) { loadingIndicator.innerHTML = message; loadingIndicator.style.display = 'block'; }
        function hideLoading() { loadingIndicator.style.display = 'none'; }
        function updateStatus(message) { statusElement.textContent = message; console.log("Status:", message); }

        // --- Initialization ---
        function checkThreeJsReady() {
            if (typeof THREE !== 'undefined' && THREE.GLTFExporter) {
                console.log("THREE.js and GLTFExporter ready.");
                threeReady = true;
                threeScene = new THREE.Scene();
                threeScene.background = new THREE.Color(0x333333);
                threeCamera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.001, 1000);
                threeCamera.position.z = 2;
            } else { updateStatus("Error: THREE.js load fail."); console.error("THREE.js or GLTFExporter not found."); threeReady = false; }
            checkAppReady();
        }

        function checkAppReady() {
            if (cvReady && threeReady) {
                updateStatus("App Ready. Init Camera.");
                initCameraButton.disabled = false;
                hideLoading();
            } else {
                let loadingMsg = "Loading:<br>";
                if (!cvReady) loadingMsg += "⏳ OpenCV<br>";
                if (!threeReady) loadingMsg += "⏳ THREE.js";
                showLoading(loadingMsg);
                console.log(`App not fully ready: cvReady=${cvReady}, threeReady=${threeReady}`);
            }
        }

        // --- Camera ---
        async function initCamera() {
            if (!cvReady) { updateStatus("OpenCV not ready for camera."); return; }
            initCameraButton.disabled = true;
            showLoading("Initializing Camera...");
            const commonConstraints = { width: { ideal: 640 }, height: { ideal: 480 }, frameRate: { ideal: 15 } };
            let videoConstraints = { ...commonConstraints, facingMode: { exact: "environment" } };
            try {
                stream = await navigator.mediaDevices.getUserMedia({ video: videoConstraints, audio: false });
                handleStreamSuccess("Rear Camera");
            } catch (err) {
                console.warn("Rear camera failed:", err.name); updateStatus("Rear cam fail. Front...");
                videoConstraints.facingMode = "user";
                try {
                    stream = await navigator.mediaDevices.getUserMedia({ video: videoConstraints, audio: false });
                    handleStreamSuccess("Front Camera");
                } catch (e2) { console.error("All cameras failed:", e2.name); updateStatus(`Cam Error: ${e2.name}`); hideLoading(); initCameraButton.disabled = false; }
            }
        }

        function handleStreamSuccess(cameraName) {
            video.srcObject = stream;
            video.onloadedmetadata = () => {
                video.play().catch(e => console.error("Video play error:", e));
                overlayCanvas.width = video.videoWidth;
                overlayCanvas.height = video.videoHeight;
                const W = video.videoWidth; const H = video.videoHeight;
                const focalLengthGuess = (W + H) / 2;
                K_matrix = cv.matFromArray(3, 3, cv.CV_64F, [focalLengthGuess, 0, W / 2, 0, focalLengthGuess, H / 2, 0, 0, 1]);
                distCoeffs = cv.Mat.zeros(4, 1, cv.CV_64F);
                updateStatus(`${cameraName} Ready. Start Scan.`);
                startScanButton.disabled = false; initCameraButton.style.display = 'none'; hideLoading();
                requestAnimationFrame(drawLoop);
            };
        }

        // --- Scanning ---
        function startScan() {
            if (!cvReady || !orb || !bfMatcher || !stream || video.paused) { updateStatus("Error: Not ready to scan."); return; }
            isScanning = true;
            scanFramesData.forEach(frame => { frame.cvKeypoints.delete(); frame.cvDescriptors.delete(); });
            scanFramesData = [];
            frameCountElement.textContent = "Frames: 0";
            startScanButton.disabled = true; stopScanButton.disabled = false;
            reconstructButton.disabled = true; exportButton.disabled = true;
            updateStatus("Scanning...");
            if (scanProcessIntervalId) clearInterval(scanProcessIntervalId);
            scanProcessIntervalId = setInterval(processFrameForScan, SCAN_INTERVAL_MS);
        }

        function stopScan() {
            isScanning = false;
            if (scanProcessIntervalId) { clearInterval(scanProcessIntervalId); scanProcessIntervalId = null; }
            startScanButton.disabled = false; stopScanButton.disabled = true;
            updateStatus(`Scan finished. ${scanFramesData.length} frames.`);
            if (scanFramesData.length >= 2) reconstructButton.disabled = false;
            if (threePointsObject) exportButton.disabled = false;
        }

        function captureCurrentFrameToMat() {
            if (!video.videoWidth || !video.videoHeight || video.paused || video.ended) return null;
            const tempReadCanvas = document.createElement('canvas');
            tempReadCanvas.width = video.videoWidth; tempReadCanvas.height = video.videoHeight;
            tempReadCanvas.getContext('2d').drawImage(video, 0, 0, video.videoWidth, video.videoHeight);
            try { return cv.imread(tempReadCanvas); } catch (e) { console.error("cv.imread error:", e); return null; }
        }

        function processFrameForScan() {
            if (!isScanning || !cvReady || !orb) return;
            let frameMat = captureCurrentFrameToMat(); if (!frameMat) return;
            let grayMat = new cv.Mat(); cv.cvtColor(frameMat, grayMat, cv.COLOR_RGBA2GRAY);
            let kpVec = new cv.KeyPointVector(); let descMat = new cv.Mat(); let mask = new cv.Mat();
            try {
                orb.detectAndCompute(grayMat, mask, kpVec, descMat);
                if (kpVec.size() > 0) {
                    scanFramesData.push({ timestamp: Date.now(), cvKeypoints: kpVec, cvDescriptors: descMat.clone() });
                    if (displayKeypointsVector) displayKeypointsVector.delete();
                    displayKeypointsVector = kpVec; // kpVec now owned by displayKeypointsVector
                } else { kpVec.delete(); descMat.delete(); }
                frameCountElement.textContent = `Frames: ${scanFramesData.length}`;
            } catch (e) {
                console.error("Error in ORB detect/compute:", e);
                if (kpVec && !kpVec.isDeleted()) kpVec.delete(); if (descMat && !descMat.isDeleted()) descMat.delete();
            } finally { frameMat.delete(); grayMat.delete(); mask.delete(); }
        }

        // --- 3D Reconstruction (SfM) ---
        async function reconstruct3D() {
            if (scanFramesData.length < 2) { updateStatus("Need at least 2 scan frames."); return; }
            if (!K_matrix) { updateStatus("Camera intrinsics not ready."); return; }
            if (!cvReady || !bfMatcher) { updateStatus("OpenCV components not ready for reconstruction."); return; }


            reconstructButton.disabled = true; exportButton.disabled = true;
            showLoading("Reconstructing 3D (SLOW)...<br>Processing Frame 1 and Last Frame.");
            await new Promise(resolve => setTimeout(resolve, 100));

            const frameA_idx = 0; const frameB_idx = scanFramesData.length - 1;
            const frameA = scanFramesData[frameA_idx]; const frameB = scanFramesData[frameB_idx];
            let points3D_final = [];
            let E, R, t, P1, P2, goodMatchesPointsA_mat, goodMatchesPointsB_mat, inlierMaskMat;

            try {
                updateStatus(`Matching ${frameA_idx} & ${frameB_idx}...`);
                let matchesVecVec = new cv.DMatchVectorVector();
                bfMatcher.knnMatch(frameA.cvDescriptors, frameB.cvDescriptors, matchesVecVec, 2);
                let goodMatches = new cv.DMatchVector(); let pts1 = [], pts2 = [];
                const ratioThresh = 0.75;
                for (let i = 0; i < matchesVecVec.size(); ++i) {
                    let mp = matchesVecVec.get(i);
                    if (mp.size() >= 2 && mp.get(0).distance < ratioThresh * mp.get(1).distance) {
                        goodMatches.push_back(mp.get(0));
                        pts1.push(frameA.cvKeypoints.get(mp.get(0).queryIdx).pt.x, frameA.cvKeypoints.get(mp.get(0).queryIdx).pt.y);
                        pts2.push(frameB.cvKeypoints.get(mp.get(0).trainIdx).pt.x, frameB.cvKeypoints.get(mp.get(0).trainIdx).pt.y);
                    }
                }
                matchesVecVec.delete();
                if (goodMatches.size() < 8) { throw new Error(`Not enough good matches: ${goodMatches.size()}`); }
                updateStatus(`${goodMatches.size()} good matches found.`);

                goodMatchesPointsA_mat = cv.matFromArray(pts1.length / 2, 1, cv.CV_32FC2, pts1);
                goodMatchesPointsB_mat = cv.matFromArray(pts2.length / 2, 1, cv.CV_32FC2, pts2);
                inlierMaskMat = new cv.Mat(); // For findEssentialMat's mask output

                updateStatus("Estimating Essential Matrix...");
                E = cv.findEssentialMat(goodMatchesPointsA_mat, goodMatchesPointsB_mat, K_matrix, cv.RANSAC, 0.999, 1.0, inlierMaskMat);
                if (E.empty()) { throw new Error("Essential Matrix computation failed."); }
                
                let inlier_count_E = 0; for(let i=0; i<inlierMaskMat.rows; ++i) if(inlierMaskMat.data[i]) inlier_count_E++;
                updateStatus(`Essential Matrix found with ${inlier_count_E} inliers.`);
                if (inlier_count_E < 8) { throw new Error(`Too few inliers for E: ${inlier_count_E}`);}


                updateStatus("Recovering Pose...");
                R = new cv.Mat(); t = new cv.Mat(); let inlierMaskPose = new cv.Mat(); // Separate mask for recoverPose
                let inliersCountPose = cv.recoverPose(E, goodMatchesPointsA_mat, goodMatchesPointsB_mat, K_matrix, R, t, inlierMaskPose);
                if (inliersCountPose === 0) { throw new Error("Recover Pose failed, no inliers."); }
                updateStatus(`Pose recovered. ${inliersCountPose} inliers for triangulation.`);

                let filteredPts1 = [], filteredPts2 = [];
                for (let i = 0; i < inlierMaskPose.rows; ++i) { // Use inlierMaskPose from recoverPose
                    if (inlierMaskPose.data[i] === 1) {
                        filteredPts1.push(pts1[i*2], pts1[i*2+1]);
                        filteredPts2.push(pts2[i*2], pts2[i*2+1]);
                    }
                }
                if (filteredPts1.length / 2 < 4) { throw new Error("Not enough inlier points after recoverPose for triangulation.");}
                let filteredPts1Mat = cv.matFromArray(filteredPts1.length / 2, 1, cv.CV_32FC2, filteredPts1);
                let filteredPts2Mat = cv.matFromArray(filteredPts2.length / 2, 1, cv.CV_32FC2, filteredPts2);

                updateStatus("Triangulating points...");
                P1 = cv.Mat.zeros(3, 4, cv.CV_64F); K_matrix.copyTo(P1.roi(new cv.Rect(0, 0, 3, 3)));
                P2 = new cv.Mat(3, 4, cv.CV_64F);
                let P2_temp_Rt = new cv.Mat(); cv.hconcat(R, t, P2_temp_Rt);
                for(let r=0; r<3; ++r) for(let c=0; c<4; ++c) { let sum=0; for(let k=0; k<3; ++k) sum += K_matrix.doubleAt(r,k) * P2_temp_Rt.doubleAt(k,c); P2.doublePtr(r,c)[0] = sum; }
                P2_temp_Rt.delete();

                let points4D = new cv.Mat();
                cv.triangulatePoints(P1, P2, filteredPts1Mat, filteredPts2Mat, points4D);
                for (let i = 0; i < points4D.cols; ++i) {
                    let W = points4D.floatAt(3, i); if (Math.abs(W) < 1e-6) continue;
                    let X = points4D.floatAt(0, i)/W, Y = points4D.floatAt(1, i)/W, Z = points4D.floatAt(2, i)/W;
                    if (Z > 0 && Z < 10) points3D_final.push(X, Y, Z);
                }
                points4D.delete(); filteredPts1Mat.delete(); filteredPts2Mat.delete(); inlierMaskPose.delete();
                updateStatus(`Triangulated ${points3D_final.length / 3} 3D points.`);
                goodMatches.delete();

            } catch (err) { updateStatus(`Error: ${err.message.substring(0,100)}`); console.error("SfM Error:", err);
            } finally {
                if (E && !E.isDeleted()) E.delete(); if (R && !R.isDeleted()) R.delete(); if (t && !t.isDeleted()) t.delete();
                if (P1 && !P1.isDeleted()) P1.delete(); if (P2 && !P2.isDeleted()) P2.delete();
                if (goodMatchesPointsA_mat && !goodMatchesPointsA_mat.isDeleted()) goodMatchesPointsA_mat.delete();
                if (goodMatchesPointsB_mat && !goodMatchesPointsB_mat.isDeleted()) goodMatchesPointsB_mat.delete();
                if (inlierMaskMat && !inlierMaskMat.isDeleted()) inlierMaskMat.delete();
                hideLoading(); reconstructButton.disabled = (scanFramesData.length < 2);
            }
            if (points3D_final.length > 0) { displaySparsePointCloud(points3D_final); exportButton.disabled = false; }
            else {
                updateStatus("No 3D points or reconstruction failed.");
                if (threePointsObject) { threeScene.remove(threePointsObject); threePointsObject.geometry.dispose(); threePointsObject.material.dispose(); threePointsObject = null; }
            }
        }

        function displaySparsePointCloud(pointsDataArray) {
             if (!threeReady) return;
             if (threePointsObject) { threeScene.remove(threePointsObject); threePointsObject.geometry.dispose(); threePointsObject.material.dispose(); }
            const geometry = new THREE.BufferGeometry();
            geometry.setAttribute('position', new THREE.Float32BufferAttribute(pointsDataArray, 3));
            const material = new THREE.PointsMaterial({ color: 0xffffff, size: 0.02 });
            threePointsObject = new THREE.Points(geometry, material);
            threeScene.add(threePointsObject);
            updateStatus(`Displaying ${pointsDataArray.length / 3} 3D points.`);
        }

        // --- Drawing & Export ---
        function drawLoop() {
            if (!stream || video.paused || video.ended) { if (stream) requestAnimationFrame(drawLoop); return; }
            overlayCtx.clearRect(0, 0, overlayCanvas.width, overlayCanvas.height);
            overlayCtx.globalAlpha = 0.5; overlayCtx.drawImage(video, 0, 0, overlayCanvas.width, overlayCanvas.height);
            overlayCtx.globalAlpha = 1.0;
            if (isScanning && displayKeypointsVector && displayKeypointsVector.size() > 0) {
                overlayCtx.fillStyle = 'white';
                for (let i = 0; i < displayKeypointsVector.size(); ++i) {
                    const kp = displayKeypointsVector.get(i);
                    overlayCtx.fillRect(kp.pt.x - 1.5, kp.pt.y - 1.5, 3, 3);
                }
            }
            requestAnimationFrame(drawLoop);
        }
        function exportGLTF() {
            if (!threeReady || !threePointsObject) { updateStatus("No 3D data to export."); return; }
            updateStatus("Exporting GLB..."); showLoading("Generating GLB...");
            const exporter = new THREE.GLTFExporter();
            exporter.parse( threePointsObject,
                function (gltf) { saveArrayBuffer(gltf, 'sparse_points.glb'); updateStatus("Sparse points GLB exported."); hideLoading(); },
                function(error) { console.error('GLTF Export Error:', error); updateStatus("GLTF Export Error."); hideLoading(); },
                { binary: true, onlyVisible: false }
            );
        }
        function saveArrayBuffer(buffer, filename) {
            const blob = new Blob([buffer], {type: 'application/octet-stream'});
            const link = document.createElement('a'); link.style.display = 'none'; document.body.appendChild(link);
            link.href = URL.createObjectURL(blob); link.download = filename; link.click();
            URL.revokeObjectURL(link.href); document.body.removeChild(link);
        }

        // --- Event Listeners & Startup ---
        window.onload = () => {
            console.log("window.onload event fired.");
            initCameraButton.disabled = true;
            showLoading("Loading App Resources...");
            checkThreeJsReady();
            // OpenCV loading is now primarily handled by onOpenCvScriptLoad and polling
            // If after a short delay, polling hasn't started (e.g. onOpenCvScriptLoad failed), start it.
            setTimeout(() => {
                if(!cvReady && !cvPollInterval) { // If not ready and not already polling
                    console.log("window.onload: Fallback - starting CV polling as it seems not to have started.");
                    startCvPolling();
                }
            }, 500);
        };
        initCameraButton.addEventListener('click', initCamera);
        startScanButton.addEventListener('click', startScan);
        stopScanButton.addEventListener('click', stopScan);
        reconstructButton.addEventListener('click', reconstruct3D);
        exportButton.addEventListener('click', exportGLTF);

    </script>
</body>
</html>
